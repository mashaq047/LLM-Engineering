
## AI Farming Advisor (LLM + Quantization + Edge Deployment)

#### ğŸ“Œ Overview
This project demonstrates how to **run a quantized Large Language Model (LLM) on resource-constrained devices** such as laptops, smartphones, or small edge devices.  
It uses the **Microsoft Phi-3 Mini Instruct** model with **8-bit quantization** (via `bitsandbytes`) to make inference lighter and faster, while maintaining useful performance.  

The chatbot is designed as an **AI Farming Advisor** that can give contextual answers, enhanced by **real-time location and weather data**.  

---

#### ğŸ¯ Key Features
- âœ… **Quantization (8-bit)** for optimized model loading on GPUs/CPUs with graceful fallbacks  
- âœ… **Custom System Prompt** â†’ â€œAI Farming Advisorâ€  
- âœ… **Context Integration** â†’ Uses IP-based location + OpenWeatherMap API for real-time weather info  
- âœ… **Streaming Chat UI** â†’ Built with **Gradio** for a responsive chatbot experience  
- âœ… **Lightweight Deployment** â†’ Potential to run on smaller devices (edge AI vision)  

---

#### âš™ï¸ Tech Stack
- [Transformers](https://huggingface.co/docs/transformers) â€“ Model loading & inference  
- [Bitsandbytes](https://github.com/TimDettmers/bitsandbytes) â€“ 8-bit quantization  
- [Torch](https://pytorch.org/) â€“ Model execution (GPU/CPU)  
- [Gradio](https://gradio.app/) â€“ Interactive chatbot UI  
- [Geocoder](https://geocoder.readthedocs.io/) â€“ Location detection  
- [OpenWeatherMap API](https://openweathermap.org/api) â€“ Weather integration  

---

#### ğŸš€ Pipeline
1. **Install Dependencies**  
   ```bash
   pip install torch transformers accelerate bitsandbytes gradio sentencepiece requests geocoder
```